{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1285136e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:36:29.240295Z",
     "iopub.status.busy": "2022-05-01T16:36:29.239785Z",
     "iopub.status.idle": "2022-05-01T16:59:24.371158Z",
     "shell.execute_reply": "2022-05-01T16:59:24.369787Z"
    },
    "papermill": {
     "duration": 1375.1656,
     "end_time": "2022-05-01T16:59:24.374264",
     "exception": false,
     "start_time": "2022-05-01T16:36:29.208664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRunning on 1 replicas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 16:36:53.163072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:53.283012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:53.284232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:53.286263: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-01 16:36:53.286625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:53.287687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:53.288741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:55.491296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:55.492324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:55.493148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 16:36:55.494731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b0 (Functional) (None, 7, 7, 1280)        4049564   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 4,052,126\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 16:37:00.709525: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "2022-05-01 16:37:15.899209: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
      "Cleanup called...\n",
      "2022-05-01 16:37:22.291896: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/135 [..............................] - ETA: 52:54"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/135 [..............................] - ETA: 5:33 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/135 [..............................] - ETA: 14:07"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/135 [..............................] - ETA: 17:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/135 [>.............................] - ETA: 18:29"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/135 [=>............................] - ETA: 20:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/135 [=>............................] - ETA: 20:20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/135 [=>............................] - ETA: 20:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/135 [==>...........................] - ETA: 20:29"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/135 [==>...........................] - ETA: 20:20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/135 [===>..........................] - ETA: 20:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24/135 [====>.........................] - ETA: 19:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/135 [====>.........................] - ETA: 19:08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/135 [====>.........................] - ETA: 18:54"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27/135 [=====>........................] - ETA: 18:39"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30/135 [=====>........................] - ETA: 18:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/135 [=====>........................] - ETA: 17:52"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/135 [======>.......................] - ETA: 17:18"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36/135 [=======>......................] - ETA: 16:57"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37/135 [=======>......................] - ETA: 16:44"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39/135 [=======>......................] - ETA: 16:18"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41/135 [========>.....................] - ETA: 15:51"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44/135 [========>.....................] - ETA: 15:18"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48/135 [=========>....................] - ETA: 14:32"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50/135 [==========>...................] - ETA: 14:12"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53/135 [==========>...................] - ETA: 13:40"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56/135 [===========>..................] - ETA: 13:06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57/135 [===========>..................] - ETA: 12:55"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58/135 [===========>..................] - ETA: 12:44"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59/135 [============>.................] - ETA: 12:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60/135 [============>.................] - ETA: 12:24"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/135 [============>.................] - ETA: 12:13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62/135 [============>.................] - ETA: 12:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63/135 [=============>................] - ETA: 11:52"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64/135 [=============>................] - ETA: 11:42"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67/135 [=============>................] - ETA: 11:10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72/135 [===============>..............] - ETA: 10:18"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78/135 [================>.............] - ETA: 9:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/135 [================>.............] - ETA: 8:59"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81/135 [=================>............] - ETA: 8:50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/135 [=================>............] - ETA: 8:20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85/135 [=================>............] - ETA: 8:09"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86/135 [==================>...........] - ETA: 7:59"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/135 [==================>...........] - ETA: 7:49"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/135 [==================>...........] - ETA: 7:39"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94/135 [===================>..........] - ETA: 6:39"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/135 [====================>.........] - ETA: 6:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98/135 [====================>.........] - ETA: 6:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/135 [=====================>........] - ETA: 5:50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/135 [======================>.......] - ETA: 4:40"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/135 [=======================>......] - ETA: 4:21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/135 [=======================>......] - ETA: 4:11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/135 [=======================>......] - ETA: 4:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/135 [========================>.....] - ETA: 3:22"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/135 [=========================>....] - ETA: 2:53"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/135 [=========================>....] - ETA: 2:43"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/135 [=========================>....] - ETA: 2:24"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/135 [==========================>...] - ETA: 2:05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/135 [==========================>...] - ETA: 1:55"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/135 [==========================>...] - ETA: 1:45"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/135 [==========================>...] - ETA: 1:35"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/135 [===========================>..] - ETA: 1:26"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/135 [===========================>..] - ETA: 1:06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n",
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/135 [===========================>..] - ETA: 57s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/135 [============================>.] - ETA: 28s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/135 [============================>.] - ETA: 18s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleanup called...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1291s 9s/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../input/shoppe-web-infer-csv/test.csv')\n",
    "\n",
    "if df.shape[0] != 3:\n",
    "\n",
    "    !pip install efficientnet -q\n",
    "    import os\n",
    "\n",
    "    import efficientnet.tfkeras as efn\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "\n",
    "    def auto_select_accelerator():\n",
    "        try:\n",
    "            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"Running on TPU:\", tpu.master())\n",
    "        except ValueError:\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "        print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "\n",
    "        return strategy\n",
    "\n",
    "\n",
    "    def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n",
    "        def decode(path):\n",
    "            file_bytes = tf.io.read_file(path)\n",
    "            if ext == 'png':\n",
    "                img = tf.image.decode_png(file_bytes, channels=3)\n",
    "            elif ext in ['jpg', 'jpeg']:\n",
    "                img = tf.image.decode_jpeg(file_bytes, channels=3)\n",
    "            else:\n",
    "                raise ValueError(\"Image extension not supported\")\n",
    "\n",
    "            img = tf.cast(img, tf.float32) / 255.0\n",
    "            img = tf.image.resize(img, target_size)\n",
    "\n",
    "            return img\n",
    "\n",
    "        def decode_with_labels(path, label):\n",
    "            return decode(path), label\n",
    "\n",
    "        return decode_with_labels if with_labels else decode\n",
    "\n",
    "\n",
    "    def build_augmenter(with_labels=True):\n",
    "        def augment(img):\n",
    "            img = tf.image.random_flip_left_right(img)\n",
    "            img = tf.image.random_flip_up_down(img)\n",
    "            return img\n",
    "\n",
    "        def augment_with_labels(img, label):\n",
    "            return augment(img), label\n",
    "\n",
    "        return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "    def build_dataset(paths, labels=None, bsize=32, cache=True,\n",
    "                      decode_fn=None, augment_fn=None,\n",
    "                      augment=True, repeat=True, shuffle=1024, \n",
    "                      cache_dir=\"\"):\n",
    "        if cache_dir != \"\" and cache is True:\n",
    "            os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "        if decode_fn is None:\n",
    "            decode_fn = build_decoder(labels is not None)\n",
    "\n",
    "        if augment_fn is None:\n",
    "            augment_fn = build_augmenter(labels is not None)\n",
    "\n",
    "        AUTO = tf.data.experimental.AUTOTUNE\n",
    "        slices = paths if labels is None else (paths, labels)\n",
    "\n",
    "        dset = tf.data.Dataset.from_tensor_slices(slices)\n",
    "        dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
    "        dset = dset.cache(cache_dir) if cache else dset\n",
    "        dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
    "        dset = dset.repeat() if repeat else dset\n",
    "        dset = dset.shuffle(shuffle) if shuffle else dset\n",
    "        dset = dset.batch(bsize).prefetch(AUTO)\n",
    "\n",
    "        return dset\n",
    "\n",
    "    COMPETITION_NAME = \"shoppe-web-csv\"\n",
    "    strategy = auto_select_accelerator()\n",
    "    BATCH_SIZE = strategy.num_replicas_in_sync * 1024\n",
    "\n",
    "    IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)\n",
    "\n",
    "    load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n",
    "    sub_df = pd.read_csv('../input/shoppe-web-infer-csv/test.csv')\n",
    "    test_paths = sub_df['path'] \n",
    "\n",
    "    sub_df['clothers'] = 0\n",
    "    sub_df['other'] = 0\n",
    "    \n",
    "\n",
    "    label_cols = sub_df.columns[8:]\n",
    "\n",
    "    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[0], IMSIZE[0]))\n",
    "    dtest = build_dataset(\n",
    "        test_paths, bsize=BATCH_SIZE, repeat=False, \n",
    "        shuffle=False, augment=False, cache=False,\n",
    "        decode_fn=test_decoder\n",
    "    )\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.models.load_model(\n",
    "            '../input/shopee-2-class-train-efnb0-2/modelb00.h5'\n",
    "        )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    sub_df[label_cols] = model.predict(dtest, verbose=1)\n",
    "    df = sub_df.copy()\n",
    "    del sub_df\n",
    "\n",
    "    df_other = df[df['other'] >= 0.5]\n",
    "    df_clothes = df[df['other'] < 0.5]\n",
    "    df_other_len = df_other.shape[0]\n",
    "    df_other = df_other.append(df_clothes).reset_index(drop=True)\n",
    "    df = df_other.copy()\n",
    "    del df_other, df_clothes\n",
    "else:\n",
    "    df['clothes'] = [0,1,0]\n",
    "    df['other'] = [1,0,1]    \n",
    "    df_other = df[df['other'] >= 0.5]\n",
    "    df_clothes = df[df['other'] < 0.5]\n",
    "    df_other = df_other.append(df_clothes).reset_index(drop=True)\n",
    "    df = df_other.copy()   \n",
    "    df_other_len = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe0c60a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:24.650394Z",
     "iopub.status.busy": "2022-05-01T16:59:24.649885Z",
     "iopub.status.idle": "2022-05-01T16:59:27.829771Z",
     "shell.execute_reply": "2022-05-01T16:59:27.828797Z"
    },
    "papermill": {
     "duration": 3.332212,
     "end_time": "2022-05-01T16:59:27.832620",
     "exception": false,
     "start_time": "2022-05-01T16:59:24.500408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7fc2dd4ecbf0 to Device at 0x7fc355e0bad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import torch\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63dbc679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:28.072757Z",
     "iopub.status.busy": "2022-05-01T16:59:28.072538Z",
     "iopub.status.idle": "2022-05-01T16:59:34.217584Z",
     "shell.execute_reply": "2022-05-01T16:59:34.216452Z"
    },
    "papermill": {
     "duration": 6.267054,
     "end_time": "2022-05-01T16:59:34.220295",
     "exception": false,
     "start_time": "2022-05-01T16:59:27.953241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import math, random\n",
    "import cv2\n",
    "import timm\n",
    "from tqdm import tqdm \n",
    "\n",
    "import albumentations as A \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "import torchvision.models as models\n",
    "from torch.nn import Parameter\n",
    "\n",
    "import gc\n",
    "import cudf, cuml, cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from transformers import (BertTokenizer, BertModel,\n",
    "                          DistilBertTokenizer, DistilBertModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f668167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:34.476011Z",
     "iopub.status.busy": "2022-05-01T16:59:34.475697Z",
     "iopub.status.idle": "2022-05-01T16:59:34.483337Z",
     "shell.execute_reply": "2022-05-01T16:59:34.482271Z"
    },
    "papermill": {
     "duration": 0.134424,
     "end_time": "2022-05-01T16:59:34.487203",
     "exception": false,
     "start_time": "2022-05-01T16:59:34.352779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this submission notebook will only be used to submit result\n"
     ]
    }
   ],
   "source": [
    "COMPUTE_CV = False\n",
    "SAVE_IMGEMBEDDING = False\n",
    "EFF_B5 = False\n",
    "ECA_NFNET_L0 = False\n",
    "MODEL_TESTING_NFNET = False\n",
    "MY_NFNET = True\n",
    "BERT = True\n",
    "DISTILBERT = False\n",
    "SAVE_DISTILBERT = False # You need to enable internet to download pretrained model\n",
    "EMBEDDING34_TH = 0.30\n",
    "\n",
    "#df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "if len(df)>3: COMPUTE_CV = False\n",
    "if COMPUTE_CV: \n",
    "    print('this submission notebook will compute CV score but commit notebook will not')\n",
    "else:\n",
    "    print('this submission notebook will only be used to submit result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65ffa59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:34.736708Z",
     "iopub.status.busy": "2022-05-01T16:59:34.735942Z",
     "iopub.status.idle": "2022-05-01T16:59:34.743324Z",
     "shell.execute_reply": "2022-05-01T16:59:34.742264Z"
    },
    "papermill": {
     "duration": 0.13642,
     "end_time": "2022-05-01T16:59:34.745453",
     "exception": false,
     "start_time": "2022-05-01T16:59:34.609033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \n",
    "    img_size = 512\n",
    "    fc_dim = 512\n",
    "    batch_size = 20\n",
    "    seed = 2020\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    classes = 11014\n",
    "    classes_other = 11014 - 3282\n",
    "    classes_clothes = 3282\n",
    "        \n",
    "    model_name = 'tf_efficientnet_b5_ns'\n",
    "    model_name2 = 'eca_nfnet_l0'\n",
    "    model_name3 = 'efficientnet_b3'\n",
    "    model_name5 = 'eca_nfnet_l0'\n",
    "    model_name6 = 'eca_nfnet_l0'\n",
    "    \n",
    "    model_path = '../input/shopee-pytorch-models/arcface_512x512_eff_b5_.pt'\n",
    "    if MODEL_TESTING_NFNET or MY_NFNET:\n",
    "        model_path2 = '../input/shopee-price-match-guarantee-embeddings/arcface_512x512_nfnet_l0(mish)_b24_15.pt'\n",
    "    else:\n",
    "        model_path2 = '../input/shopee-pytorch-models/arcface_512x512_nfnet_l0 (mish).pt'\n",
    "    model_path3 = '../input/shopee-pytorch-models/arcface_512x512_eff_b3.pt'\n",
    "    model_path5 = '../input/other-eca-nfnet-l0-training-21ep/arcface_512x512_nfnet_l0(mish)19.pt'\n",
    "    model_path6 = '../input/clothes-eca-nfnet-l0-training-30ep/arcface_512x512_nfnet_l0(mish)28.pt'\n",
    "    scale = 30 \n",
    "    margin = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9191aba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:34.991339Z",
     "iopub.status.busy": "2022-05-01T16:59:34.991076Z",
     "iopub.status.idle": "2022-05-01T16:59:35.001437Z",
     "shell.execute_reply": "2022-05-01T16:59:35.000616Z"
    },
    "papermill": {
     "duration": 0.136067,
     "end_time": "2022-05-01T16:59:35.003598",
     "exception": false,
     "start_time": "2022-05-01T16:59:34.867531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset(COMPUTE_CV,df = df):\n",
    "    \n",
    "    if COMPUTE_CV:\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = df['path']\n",
    "    \n",
    "    else:\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = df['path']\n",
    "\n",
    "    return df, df_cu, image_paths\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73bad8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:35.249989Z",
     "iopub.status.busy": "2022-05-01T16:59:35.249673Z",
     "iopub.status.idle": "2022-05-01T16:59:35.258355Z",
     "shell.execute_reply": "2022-05-01T16:59:35.257299Z"
    },
    "papermill": {
     "duration": 0.135013,
     "end_time": "2022-05-01T16:59:35.260472",
     "exception": false,
     "start_time": "2022-05-01T16:59:35.125459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'], row['phash_predictions']])\n",
    "    return ' '.join( np.unique(x))\n",
    "def combine_for_cv(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'], row['phash_predictions']])\n",
    "    return np.unique(x)\n",
    "def combine_predictions_BERT(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'], row['phash_predictions'], row['text_predictions_BERT']])\n",
    "    return ' '.join( np.unique(x))\n",
    "def combine_for_cv_BERT(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'], row['phash_predictions'], row['text_predictions_BERT']])\n",
    "    return np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0e155b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:35.514002Z",
     "iopub.status.busy": "2022-05-01T16:59:35.513310Z",
     "iopub.status.idle": "2022-05-01T16:59:35.518450Z",
     "shell.execute_reply": "2022-05-01T16:59:35.517547Z"
    },
    "papermill": {
     "duration": 0.130479,
     "end_time": "2022-05-01T16:59:35.520521",
     "exception": false,
     "start_time": "2022-05-01T16:59:35.390042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getMetric(col):\n",
    "    def f1score(row):\n",
    "        n = len(np.intersect1d(row.target, row[col]))\n",
    "        return 2*n / (len(row.target) + len(row[col]))\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdda933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:35.950024Z",
     "iopub.status.busy": "2022-05-01T16:59:35.949525Z",
     "iopub.status.idle": "2022-05-01T16:59:35.957520Z",
     "shell.execute_reply": "2022-05-01T16:59:35.956028Z"
    },
    "papermill": {
     "duration": 0.262923,
     "end_time": "2022-05-01T16:59:35.960835",
     "exception": false,
     "start_time": "2022-05-01T16:59:35.697912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_transforms():\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(CFG.img_size,CFG.img_size,always_apply=True),\n",
    "            A.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d41f5aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:36.344262Z",
     "iopub.status.busy": "2022-05-01T16:59:36.343998Z",
     "iopub.status.idle": "2022-05-01T16:59:36.351271Z",
     "shell.execute_reply": "2022-05-01T16:59:36.350302Z"
    },
    "papermill": {
     "duration": 0.170299,
     "end_time": "2022-05-01T16:59:36.353350",
     "exception": false,
     "start_time": "2022-05-01T16:59:36.183051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_paths.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']       \n",
    "    \n",
    "        return image,torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c49f51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:36.599091Z",
     "iopub.status.busy": "2022-05-01T16:59:36.598817Z",
     "iopub.status.idle": "2022-05-01T16:59:36.677786Z",
     "shell.execute_reply": "2022-05-01T16:59:36.676766Z"
    },
    "papermill": {
     "duration": 0.201444,
     "end_time": "2022-05-01T16:59:36.680342",
     "exception": false,
     "start_time": "2022-05-01T16:59:36.478898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "class ShopeeModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes,\n",
    "        model_name = CFG.model_name,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = False,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'nfnet_f3':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ShopeeModel2(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes,\n",
    "        model_name = CFG.model_name2,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel2,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'eca_nfnet_l0':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ShopeeModel3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name = CFG.model_name3,\n",
    "        n_classes = CFG.classes,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel3,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'eca_nfnet_l0':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ShopeeModel5(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes_other,\n",
    "        model_name = CFG.model_name5,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel5,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'eca_nfnet_l0':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ShopeeModel6(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes_clothes,\n",
    "        model_name = CFG.model_name6,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel6,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'eca_nfnet_l0':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d5b37d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:36.927597Z",
     "iopub.status.busy": "2022-05-01T16:59:36.927325Z",
     "iopub.status.idle": "2022-05-01T16:59:36.939058Z",
     "shell.execute_reply": "2022-05-01T16:59:36.938060Z"
    },
    "papermill": {
     "duration": 0.13572,
     "end_time": "2022-05-01T16:59:36.941090",
     "exception": false,
     "start_time": "2022-05-01T16:59:36.805370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/parthdhameliya77/pytorch-eca-nfnet-l0-image-tfidf-inference\n",
    "class Mish_func(torch.autograd.Function):\n",
    "    \n",
    "    \"\"\"from: https://github.com/tyunist/memory_efficient_mish_swish/blob/master/mish.py\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.tanh(F.softplus(i))\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "  \n",
    "        v = 1. + i.exp()\n",
    "        h = v.log() \n",
    "        grad_gh = 1./h.cosh().pow_(2) \n",
    "\n",
    "        # Note that grad_hv * grad_vx = sigmoid(x)\n",
    "        #grad_hv = 1./v  \n",
    "        #grad_vx = i.exp()\n",
    "        \n",
    "        grad_hx = i.sigmoid()\n",
    "\n",
    "        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n",
    "        \n",
    "        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n",
    "        \n",
    "        return grad_output * grad_f \n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    def forward(self, input_tensor):\n",
    "        return Mish_func.apply(input_tensor)\n",
    "\n",
    "\n",
    "def replace_activations(model, existing_layer, new_layer):\n",
    "    \n",
    "    \"\"\"A function for replacing existing activation layers\"\"\"\n",
    "    \n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n",
    "\n",
    "        if type(module) == existing_layer:\n",
    "            layer_old = module\n",
    "            layer_new = new_layer\n",
    "            model._modules[name] = layer_new\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb160ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:37.189113Z",
     "iopub.status.busy": "2022-05-01T16:59:37.188851Z",
     "iopub.status.idle": "2022-05-01T16:59:37.215729Z",
     "shell.execute_reply": "2022-05-01T16:59:37.214845Z"
    },
    "papermill": {
     "duration": 0.154015,
     "end_time": "2022-05-01T16:59:37.217899",
     "exception": false,
     "start_time": "2022-05-01T16:59:37.063884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings(image_paths, model_name=CFG.model_name, EFF_B5=EFF_B5, nfnet_only=False):\n",
    "    \n",
    "    if EFF_B5 and not nfnet_only:\n",
    "        embeds = []\n",
    "\n",
    "        model = ShopeeModel(model_name = model_name)\n",
    "        model.eval()\n",
    "        model.load_state_dict(torch.load(CFG.model_path))\n",
    "        model = model.to(CFG.device)\n",
    "\n",
    "        image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "        image_loader = DataLoader(\n",
    "            image_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for img,label in tqdm(image_loader): \n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "                feat = model(img,label)\n",
    "                image_embeddings = feat.detach().cpu().numpy()\n",
    "                embeds.append(image_embeddings)\n",
    "\n",
    "\n",
    "        del model, image_embeddings\n",
    "        image_embeddings1 = np.concatenate(embeds)\n",
    "        print(f'image embeddings1 shape is {image_embeddings1.shape}')\n",
    "        del embeds\n",
    "        gc.collect()\n",
    "        \n",
    "    else: image_embeddings1 = None\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    model = ShopeeModel2()\n",
    "    model.eval()\n",
    "    model = replace_activations(model, torch.nn.SiLU, Mish())\n",
    "\n",
    "    model.load_state_dict(torch.load(CFG.model_path2))\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    embeds2 = []\n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds2.append(image_embeddings)\n",
    "    \n",
    "    del model\n",
    "    image_embeddings3 = np.concatenate(embeds2)\n",
    "    print(f'image embeddings3 shape is {image_embeddings3.shape}')\n",
    "    del embeds2\n",
    "    gc.collect()\n",
    "    \n",
    "    #---\n",
    "    if not nfnet_only:\n",
    "        embeds = []\n",
    "\n",
    "        model = ShopeeModel3()\n",
    "        model.eval()\n",
    "        model.load_state_dict(torch.load(CFG.model_path3))\n",
    "        model = model.to(CFG.device)\n",
    "\n",
    "\n",
    "        image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "        image_loader = DataLoader(\n",
    "            image_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for img,label in tqdm(image_loader): \n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "                feat = model(img,label)\n",
    "                image_embeddings = feat.detach().cpu().numpy()\n",
    "                embeds.append(image_embeddings)\n",
    "\n",
    "\n",
    "        del model\n",
    "        image_embeddings4 = np.concatenate(embeds)\n",
    "        print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "        del embeds\n",
    "        gc.collect()    \n",
    "\n",
    "    else: image_embeddings4 = None\n",
    "\n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeModel5()\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(CFG.model_path5))\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "\n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "    \n",
    "    \n",
    "    del model\n",
    "    image_embeddings5 = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect() \n",
    "    \n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeModel6()\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(CFG.model_path6))\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "\n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "    \n",
    "    \n",
    "    del model\n",
    "    image_embeddings6 = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect() \n",
    "    return image_embeddings1, image_embeddings3, image_embeddings4, image_embeddings5, image_embeddings6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4923c009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:37.457818Z",
     "iopub.status.busy": "2022-05-01T16:59:37.457220Z",
     "iopub.status.idle": "2022-05-01T16:59:37.464529Z",
     "shell.execute_reply": "2022-05-01T16:59:37.463408Z"
    },
    "papermill": {
     "duration": 0.129862,
     "end_time": "2022-05-01T16:59:37.467662",
     "exception": false,
     "start_time": "2022-05-01T16:59:37.337800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.626656636805033"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold shifting depending on dataset length\n",
    "# https://www.kaggle.com/c/shopee-product-matching/discussion/234927\n",
    "def dataset_th(known_th, known_dataset_len, new_dataset_len):\n",
    "    return (-2.051562606852219e-06 * (new_dataset_len-known_dataset_len)) + known_th\n",
    "\n",
    "dataset_th(1.7, 34250, 70000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240781a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:37.726766Z",
     "iopub.status.busy": "2022-05-01T16:59:37.726135Z",
     "iopub.status.idle": "2022-05-01T16:59:37.743243Z",
     "shell.execute_reply": "2022-05-01T16:59:37.742340Z"
    },
    "papermill": {
     "duration": 0.15292,
     "end_time": "2022-05-01T16:59:37.745330",
     "exception": false,
     "start_time": "2022-05-01T16:59:37.592410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_predictions_other(df, embeddings1, embeddings3, embeddings34, \n",
    "                          EFF_B5=EFF_B5, ECA_NFNET_L0=ECA_NFNET_L0, predictions34_th=0.36):\n",
    "    \n",
    "    if len(df) > 3:\n",
    "        KNN = 50\n",
    "    else : \n",
    "        KNN = 3\n",
    "    \n",
    "    #--\n",
    "    if EFF_B5:\n",
    "        model = NearestNeighbors(n_neighbors = KNN)\n",
    "        model.fit(embeddings1)\n",
    "        distances, indices = model.kneighbors(embeddings1)\n",
    "\n",
    "        threshold = 1.7 - 0.2978\n",
    "        predictions1 = []\n",
    "        for k in tqdm(range(0, df_other_len)):\n",
    "            idx = np.where(distances[k,] < threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = list(df['posting_id'].iloc[ids])\n",
    "            # for ii in np.arange(1.7-0.2978, (1.7-0.2978)*1.5, 0.04):\n",
    "                # if ii < (1.7-0.2978)*1.5 and len(posting_ids) <= 1:\n",
    "                    # idx = np.where(distances[k,] < ii)[0]\n",
    "                    # ids = indices[k,idx]\n",
    "                    # posting_ids = list(df['posting_id'].iloc[ids].values)  \n",
    "            predictions1.append(posting_ids)\n",
    "\n",
    "        del model, distances, indices, embeddings1\n",
    "        gc.collect()\n",
    "\n",
    "    #--\n",
    "    if ECA_NFNET_L0:\n",
    "        model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
    "        model.fit(embeddings3)\n",
    "        distances, indices = model.kneighbors(embeddings3)\n",
    "\n",
    "        threshold=0.36\n",
    "        predictions3 = []\n",
    "        for k in tqdm(range((0, df_other_len))):\n",
    "            idx = np.where(distances[k,] < threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = list(df['posting_id'].iloc[ids])\n",
    "            predictions3.append(posting_ids)\n",
    "\n",
    "        del model, distances, indices, embeddings3\n",
    "        gc.collect()    \n",
    "    #--\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
    "    model.fit(embeddings34)\n",
    "    distances, indices = model.kneighbors(embeddings34)\n",
    "    \n",
    "    predictions34 = []\n",
    "    for k in tqdm(range(0, df_other_len)):\n",
    "        idx = np.where(distances[k,] < predictions34_th)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = list(df['posting_id'].iloc[ids].values)\n",
    "        for ii in np.arange(predictions34_th, 1.5, 0.1):\n",
    "            #print(ii)\n",
    "            if len(posting_ids) <= 5:\n",
    "                idx = np.where(distances[k,] < ii)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = list(df['posting_id'].iloc[ids].values) \n",
    "            else:\n",
    "                break\n",
    "        predictions34.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    \n",
    "    # combine predictions(i.e. image IDs) of all the models & remove the duplicates.\n",
    "    # we can try & experiment here to combine different models here..\n",
    "    if EFF_B5 and ECA_NFNET_L0:\n",
    "        predictions = [list(set(a + c + d)) for a, c, d in zip(predictions1, predictions3, predictions34)]\n",
    "    elif EFF_B5:\n",
    "        predictions = [list(set(a + d)) for a, d in zip(predictions1, predictions34)]\n",
    "    else:\n",
    "        predictions = predictions34\n",
    "\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6c2fe3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:37.988558Z",
     "iopub.status.busy": "2022-05-01T16:59:37.987789Z",
     "iopub.status.idle": "2022-05-01T16:59:38.004987Z",
     "shell.execute_reply": "2022-05-01T16:59:38.004000Z"
    },
    "papermill": {
     "duration": 0.139935,
     "end_time": "2022-05-01T16:59:38.007059",
     "exception": false,
     "start_time": "2022-05-01T16:59:37.867124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_predictions_clothes(df, embeddings1, embeddings3, embeddings34, \n",
    "                          EFF_B5=EFF_B5, ECA_NFNET_L0=ECA_NFNET_L0, predictions34_th=0.36):\n",
    "    \n",
    "    if len(df) > 3:\n",
    "        KNN = 50\n",
    "    else : \n",
    "        KNN = 3\n",
    "    \n",
    "    #--\n",
    "    if EFF_B5:\n",
    "        model = NearestNeighbors(n_neighbors = KNN)\n",
    "        model.fit(embeddings1)\n",
    "        distances, indices = model.kneighbors(embeddings1)\n",
    "\n",
    "        threshold = 1.7 - 0.2978\n",
    "        predictions1 = []\n",
    "        for k in tqdm(range(df_other_len, df.shape[0])):\n",
    "            idx = np.where(distances[k,] < threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = list(df['posting_id'].iloc[ids])\n",
    "            # for ii in np.arange(1.7-0.2978, (1.7-0.2978)*1.5, 0.04):\n",
    "                # if ii < (1.7-0.2978)*1.5 and len(posting_ids) <= 1:\n",
    "                    # idx = np.where(distances[k,] < ii)[0]\n",
    "                    # ids = indices[k,idx]\n",
    "                    # posting_ids = list(df['posting_id'].iloc[ids].values)  \n",
    "            predictions1.append(posting_ids)\n",
    "\n",
    "        del model, distances, indices, embeddings1\n",
    "        gc.collect()\n",
    "\n",
    "    #--\n",
    "    if ECA_NFNET_L0:\n",
    "        model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
    "        model.fit(embeddings3)\n",
    "        distances, indices = model.kneighbors(embeddings3)\n",
    "\n",
    "        threshold=0.36\n",
    "        predictions3 = []\n",
    "        for k in tqdm(range(df_other_len, df.shape[0])):\n",
    "            idx = np.where(distances[k,] < threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = list(df['posting_id'].iloc[ids])\n",
    "            predictions3.append(posting_ids)\n",
    "\n",
    "        del model, distances, indices, embeddings3\n",
    "        gc.collect()    \n",
    "    #--\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
    "    model.fit(embeddings34)\n",
    "    distances, indices = model.kneighbors(embeddings34)\n",
    "    \n",
    "    predictions34 = []\n",
    "    for k in tqdm(range(df_other_len, df.shape[0])):\n",
    "        idx = np.where(distances[k,] < predictions34_th)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = list(df['posting_id'].iloc[ids].values)\n",
    "        for ii in np.arange(predictions34_th, 1.5, 0.1):\n",
    "            #print(ii)\n",
    "            if len(posting_ids) <= 5:\n",
    "                idx = np.where(distances[k,] < ii)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = list(df['posting_id'].iloc[ids].values) \n",
    "            else:\n",
    "                break    \n",
    "        predictions34.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    \n",
    "    # combine predictions(i.e. image IDs) of all the models & remove the duplicates.\n",
    "    # we can try & experiment here to combine different models here..\n",
    "    if EFF_B5 and ECA_NFNET_L0:\n",
    "        predictions = [list(set(a + c + d)) for a, c, d in zip(predictions1, predictions3, predictions34)]\n",
    "    elif EFF_B5:\n",
    "        predictions = [list(set(a + d)) for a, d in zip(predictions1, predictions34)]\n",
    "    else:\n",
    "        predictions = predictions34\n",
    "\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fac327b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:38.260849Z",
     "iopub.status.busy": "2022-05-01T16:59:38.260088Z",
     "iopub.status.idle": "2022-05-01T16:59:45.625802Z",
     "shell.execute_reply": "2022-05-01T16:59:45.621900Z"
    },
    "papermill": {
     "duration": 7.498205,
     "end_time": "2022-05-01T16:59:45.628497",
     "exception": false,
     "start_time": "2022-05-01T16:59:38.130292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "      <th>sort_by_rank</th>\n",
       "      <th>sales_volume</th>\n",
       "      <th>path</th>\n",
       "      <th>clothers</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girls_clothes0002</td>\n",
       "      <td>台灣現貨 A027  海棉胸墊 內衣胸墊 泳衣胸墊 比基尼胸墊 上薄下厚胸墊 集中胸墊 增厚...</td>\n",
       "      <td>cb40c72c7288c7755f8e26e125910468</td>\n",
       "      <td>29</td>\n",
       "      <td>girls_clothes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/shoppe-web-dataset1/girls_clothes0002...</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.998049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girls_clothes0005</td>\n",
       "      <td>衝浪繩正宗泰國進口蠶絲蠟線 不退色 可帶著洗澡手作diy材料☆水晶森林手創館☆</td>\n",
       "      <td>1b171686050e6fafee1bb666ba62d76c</td>\n",
       "      <td>30</td>\n",
       "      <td>girls_clothes</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/shoppe-web-dataset1/girls_clothes0005...</td>\n",
       "      <td>0.162054</td>\n",
       "      <td>0.837946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girls_clothes0007</td>\n",
       "      <td>★ 現貨在台 24H內出貨 ★【伊代】一次性乳貼 透氣乳貼 防凸點貼 防走光 乳暈貼 乳頭貼...</td>\n",
       "      <td>577d9263ad55f154524882f8830a574b</td>\n",
       "      <td>1</td>\n",
       "      <td>girls_clothes</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/shoppe-web-dataset1/girls_clothes0007...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.999962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>girls_clothes0008</td>\n",
       "      <td>🥀旺斯女孩🥀歐美一次性胸貼 乳貼 不織布材質 隱形透氣乳貼  防凸點貼 防走光 防凸點 無痕...</td>\n",
       "      <td>25be8b3cb3fe64a58973eb4d1a6aef0c</td>\n",
       "      <td>3</td>\n",
       "      <td>girls_clothes</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/shoppe-web-dataset1/girls_clothes0008...</td>\n",
       "      <td>0.149889</td>\n",
       "      <td>0.850111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>girls_clothes0013</td>\n",
       "      <td>【A】《3排3扣》特價＊台灣現貨免縫內衣延長背扣／內衣扣延長扣加長扣／內衣太緊背勾排扣胸罩文...</td>\n",
       "      <td>23cd7a3db17ec335babe4436a4638358</td>\n",
       "      <td>4</td>\n",
       "      <td>girls_clothes</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/shoppe-web-dataset1/girls_clothes0013...</td>\n",
       "      <td>0.183548</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          posting_id                                               name  \\\n",
       "0  girls_clothes0002  台灣現貨 A027  海棉胸墊 內衣胸墊 泳衣胸墊 比基尼胸墊 上薄下厚胸墊 集中胸墊 增厚...   \n",
       "1  girls_clothes0005            衝浪繩正宗泰國進口蠶絲蠟線 不退色 可帶著洗澡手作diy材料☆水晶森林手創館☆   \n",
       "2  girls_clothes0007  ★ 現貨在台 24H內出貨 ★【伊代】一次性乳貼 透氣乳貼 防凸點貼 防走光 乳暈貼 乳頭貼...   \n",
       "3  girls_clothes0008  🥀旺斯女孩🥀歐美一次性胸貼 乳貼 不織布材質 隱形透氣乳貼  防凸點貼 防走光 防凸點 無痕...   \n",
       "4  girls_clothes0013  【A】《3排3扣》特價＊台灣現貨免縫內衣延長背扣／內衣扣延長扣加長扣／內衣太緊背勾排扣胸罩文...   \n",
       "\n",
       "                              image  price       category  sort_by_rank  \\\n",
       "0  cb40c72c7288c7755f8e26e125910468     29  girls_clothes             2   \n",
       "1  1b171686050e6fafee1bb666ba62d76c     30  girls_clothes             5   \n",
       "2  577d9263ad55f154524882f8830a574b      1  girls_clothes             7   \n",
       "3  25be8b3cb3fe64a58973eb4d1a6aef0c      3  girls_clothes             8   \n",
       "4  23cd7a3db17ec335babe4436a4638358      4  girls_clothes            13   \n",
       "\n",
       "   sales_volume                                               path  clothers  \\\n",
       "0             0  ../input/shoppe-web-dataset1/girls_clothes0002...  0.001951   \n",
       "1             0  ../input/shoppe-web-dataset1/girls_clothes0005...  0.162054   \n",
       "2             0  ../input/shoppe-web-dataset1/girls_clothes0007...  0.000038   \n",
       "3             0  ../input/shoppe-web-dataset1/girls_clothes0008...  0.149889   \n",
       "4             0  ../input/shoppe-web-dataset1/girls_clothes0013...  0.183548   \n",
       "\n",
       "      other  \n",
       "0  0.998049  \n",
       "1  0.837946  \n",
       "2  0.999962  \n",
       "3  0.850111  \n",
       "4  0.816452  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, df_cu, image_paths = read_dataset(COMPUTE_CV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61238a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T16:59:45.961023Z",
     "iopub.status.busy": "2022-05-01T16:59:45.960697Z",
     "iopub.status.idle": "2022-05-01T20:42:58.650897Z",
     "shell.execute_reply": "2022-05-01T20:42:58.649681Z"
    },
    "papermill": {
     "duration": 13392.856854,
     "end_time": "2022-05-01T20:42:58.653254",
     "exception": false,
     "start_time": "2022-05-01T16:59:45.796400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for eca_nfnet_l0 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "100%|██████████| 6900/6900 [56:23<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image embeddings3 shape is (138000, 512)\n",
      "Building Model Backbone for efficientnet_b3 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6900/6900 [54:05<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (20, 512)\n",
      "Building Model Backbone for eca_nfnet_l0 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6900/6900 [56:01<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (20, 512)\n",
      "Building Model Backbone for eca_nfnet_l0 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6900/6900 [56:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (20, 512)\n"
     ]
    }
   ],
   "source": [
    "if not COMPUTE_CV or SAVE_IMGEMBEDDING:\n",
    "    image_embeddings1, image_embeddings3, image_embeddings4, image_embeddings5, image_embeddings6 = get_image_embeddings(image_paths.values, nfnet_only=MODEL_TESTING_NFNET if COMPUTE_CV else COMPUTE_CV)\n",
    "    if SAVE_IMGEMBEDDING and not MODEL_TESTING_NFNET: \n",
    "        np.savetxt('tf_efficientnet_b5_ns.csv', image_embeddings1, delimiter=',')\n",
    "        np.savetxt('eca_nfnet_l0.csv', image_embeddings3, delimiter=',')\n",
    "        np.savetxt('efficientnet_b3.csv', image_embeddings4, delimiter=',')\n",
    "    elif COMPUTE_CV and MODEL_TESTING_NFNET:\n",
    "        image_embeddings1 = np.loadtxt('../input/shopee-price-match-guarantee-embeddings/tf_efficientnet_b5_ns.csv', delimiter=',')\n",
    "        np.savetxt('eca_nfnet_l0_b24_15.csv', image_embeddings3, delimiter=',')\n",
    "        image_embeddings4 = np.loadtxt('../input/shopee-price-match-guarantee-embeddings/efficientnet_b3.csv', delimiter=',')\n",
    "else:\n",
    "    if EFF_B5:\n",
    "        image_embeddings1 = np.loadtxt('../input/shopee-price-match-guarantee-embeddings/tf_efficientnet_b5_ns.csv', delimiter=',')\n",
    "    image_embeddings3 = np.loadtxt('../input/shopee-price-match-guarantee-embeddings/eca_nfnet_l0_b24_15.csv', delimiter=',')\n",
    "    image_embeddings4 = np.loadtxt('../input/shopee-price-match-guarantee-embeddings/efficientnet_b3.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee02222e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T20:43:21.147790Z",
     "iopub.status.busy": "2022-05-01T20:43:21.147450Z",
     "iopub.status.idle": "2022-05-01T20:43:25.365747Z",
     "shell.execute_reply": "2022-05-01T20:43:25.362541Z"
    },
    "papermill": {
     "duration": 15.556911,
     "end_time": "2022-05-01T20:43:25.370938",
     "exception": false,
     "start_time": "2022-05-01T20:43:09.814027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_embeddings_other = image_embeddings3 / 3 + image_embeddings4 / 3  + image_embeddings5 / 3\n",
    "image_embeddings_clothes = image_embeddings3 / 3 + image_embeddings4 / 3  + image_embeddings6 / 3\n",
    "del image_embeddings4,image_embeddings5,image_embeddings6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55771bb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T20:43:49.084161Z",
     "iopub.status.busy": "2022-05-01T20:43:49.083588Z",
     "iopub.status.idle": "2022-05-01T20:46:32.391313Z",
     "shell.execute_reply": "2022-05-01T20:46:32.390222Z"
    },
    "papermill": {
     "duration": 174.785541,
     "end_time": "2022-05-01T20:46:32.394741",
     "exception": false,
     "start_time": "2022-05-01T20:43:37.609200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "other_emb = pd.DataFrame(image_embeddings_other).to_csv('other_emb.csv', index = False)\n",
    "del other_emb\n",
    "clothes_emb = pd.DataFrame(image_embeddings_other).to_csv('clothes_emb.csv', index = False)\n",
    "del clothes_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5534682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T20:46:56.701395Z",
     "iopub.status.busy": "2022-05-01T20:46:56.700923Z",
     "iopub.status.idle": "2022-05-01T20:49:19.073063Z",
     "shell.execute_reply": "2022-05-01T20:49:19.071286Z"
    },
    "papermill": {
     "duration": 154.337315,
     "end_time": "2022-05-01T20:49:19.076080",
     "exception": false,
     "start_time": "2022-05-01T20:46:44.738765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96485/96485 [01:31<00:00, 1056.11it/s]\n",
      "100%|██████████| 41515/41515 [00:42<00:00, 980.26it/s] \n"
     ]
    }
   ],
   "source": [
    "image_predictions_other = get_image_predictions_other(df, image_embeddings1, image_embeddings3, image_embeddings_other, \n",
    "                                          predictions34_th=EMBEDDING34_TH)\n",
    "image_predictions_clothes = get_image_predictions_clothes(df, image_embeddings1, image_embeddings3, image_embeddings_clothes, \n",
    "                                          predictions34_th=EMBEDDING34_TH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f33c65e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T20:49:43.871489Z",
     "iopub.status.busy": "2022-05-01T20:49:43.871148Z",
     "iopub.status.idle": "2022-05-01T20:49:43.877854Z",
     "shell.execute_reply": "2022-05-01T20:49:43.876938Z"
    },
    "papermill": {
     "duration": 12.064498,
     "end_time": "2022-05-01T20:49:43.879835",
     "exception": false,
     "start_time": "2022-05-01T20:49:31.815337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_predictions_other.extend(image_predictions_clothes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbebea20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T20:50:08.567568Z",
     "iopub.status.busy": "2022-05-01T20:50:08.567160Z",
     "iopub.status.idle": "2022-05-01T20:50:08.576220Z",
     "shell.execute_reply": "2022-05-01T20:50:08.574908Z"
    },
    "papermill": {
     "duration": 12.717587,
     "end_time": "2022-05-01T20:50:08.578752",
     "exception": false,
     "start_time": "2022-05-01T20:49:55.861165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_predictions = image_predictions_other.copy()\n",
    "del image_predictions_other, image_predictions_clothes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f18e3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T20:50:33.006980Z",
     "iopub.status.busy": "2022-05-01T20:50:33.005497Z",
     "iopub.status.idle": "2022-05-01T20:50:38.046394Z",
     "shell.execute_reply": "2022-05-01T20:50:38.045444Z"
    },
    "papermill": {
     "duration": 17.64181,
     "end_time": "2022-05-01T20:50:38.048737",
     "exception": false,
     "start_time": "2022-05-01T20:50:20.406927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girls_clothes0001</td>\n",
       "      <td>[girls_clothes0001, girls_clothes2609, girls_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girls_clothes0002</td>\n",
       "      <td>[girls_clothes0002, girls_clothes4255, girls_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girls_clothes0003</td>\n",
       "      <td>[girls_clothes0003, girls_clothes2800, girls_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>girls_clothes0004</td>\n",
       "      <td>[girls_clothes0004, home_life3077, beauty_care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>girls_clothes0005</td>\n",
       "      <td>[girls_clothes0005, cultural_and_creative_prod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_id                                            similar\n",
       "0  girls_clothes0001  [girls_clothes0001, girls_clothes2609, girls_c...\n",
       "1  girls_clothes0002  [girls_clothes0002, girls_clothes4255, girls_c...\n",
       "2  girls_clothes0003  [girls_clothes0003, girls_clothes2800, girls_c...\n",
       "3  girls_clothes0004  [girls_clothes0004, home_life3077, beauty_care...\n",
       "4  girls_clothes0005  [girls_clothes0005, cultural_and_creative_prod..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['similar'] = image_predictions\n",
    "\n",
    "df1 = pd.read_csv('../input/shoppe-web-infer-csv/test.csv')    \n",
    "df1 = df1['posting_id'] \n",
    "df = pd.merge(df1, df, on = 'posting_id', how = 'left')\n",
    "df = df.rename(columns={'posting_id':'item_id'})\n",
    "df[['item_id', 'similar']].to_csv('similar.csv', index = False)\n",
    "df[['item_id', 'similar']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15274.820372,
   "end_time": "2022-05-01T20:50:54.222903",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-01T16:36:19.402531",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
